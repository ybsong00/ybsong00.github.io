<!DOCTYPE html>
<html>
<head>
<title>ybsong</title>

<style media="screen" type="text/css">
body
{
  border: 0pt none;
  font-family: inherit;
  font-size: 100%;
  font-style: inherit;
  font-weight: inherit;
  margin: 0pt;
  outline-color: invert;
  outline-style: none;
  outline-width: 0pt;
  padding: 0pt;
  vertical-align: baseline;
}
body {
  position: relative;
  margin: 3em auto 2em auto;
  width: 1080px;
  font-family: Times New Roman, Lato, Verdana, Helvetica, sans-serif;
  font-size: 14px;
  background: #fdfdfd;
}
</style>

</head>

<body>
		
	<table align="center" cellspacing="10">
	<tr>
	<td align="center"><img border=0 height=204 width=200 src="ybsong.png"></td>
	<td align="center">
			<td align="center"><h2>Yibing Song</h2>
			<p><font size=+1>&#23435;&#22869;&#20853;</font></p>
			<p><font size=+1>Computer Vision Researcher<br/>Tencent AI Lab</font></p>						
			<p>Email: yibingsong.cv at gmail dot com<br></p>
			</td>			
	</td>		
	</tr>
	</table>
	
	<h2>Biography</h2>
	<hr/>
	<p><font size="3">Yibing Song currently works for Tencent. He has obtained PhD/Mphil degrees from City University of Hong Kong in 2018/2014 and a bachelor degree from University of Science and Technology of China in 2011. During graduate study, he has interned in Adobe Research, San Jose and visited UC Merced. 
	Yibing Song works on the fundamental visual recognitions that develop pioneer neural architectures with representation learning. Meanwhile, he is interested in emerging visual generations with single or multiple modalities.</font></p>
		
	<br>
	
	<h2>Service Highlights</h2>
	<hr>
	<p><font size="3">Area Chair: NeurIPS 2022, ICLR (2023, 2022), WACV 2023.</font></p>		
	<p><font size="3">Outstanding Reviewer: CVPR (2020, 2019, 2018).</font></p>
	<p><font size="3">Top Reviewer: NeurIPS 2019.</font></p>
	<br>	
	
	<h2>3 Representative Publications &nbsp
	<a href="pubs.html">[More]</a>
	<a href="http://scholar.google.com/citations?user=oRhJHmIAAAAJ"><strong>[Citations]</strong></a></h2>
	<hr>
	<table cellspacing="10">
	<tbody>
		
		
		<tr>
			<td><center><img width="300" src="coming_soon.png"></center></td>
			<td>
			<font size="3">VideoMAE: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training,
			<br>
			<i>Zhan Tong, <b>Yibing Song</b>, Jue Wang, and Limin Wang,</i>
			<br>
			Advances in Neural Information Processing Systems (<b>NeurIPS</b>) 2022
			<br>
			[<a href='https://arxiv.org/abs/2203.12602'><b>PDF</b></a>|<a href='https://github.com/MCG-NJU/VideoMAE'><b>Project Page</b></a>] 
			</td>			
		</tr>
		
		
		<tr>
			<td><center><img width="300" src="coming_soon.png"></center></td>
			<td bgcolor="#e9eaed">
			<font size="3">One Model to Edit Them All: Free-Form Text-Driven Image Manipulation with Semantic Modulations,
			<br>
			<i>Yiming Zhu, Hongyu Liu, <b>Yibing Song</b>, Ziyang Yuan, Xintong Han, Chun Yuan, Qifeng Chen, and Jue Wang,</i>
			<br>
			Advances in Neural Information Processing Systems (<b>NeurIPS</b>) 2022
			<br>
			[PDF|Project Page]
			</td>			
		</tr>
		
		
		<tr>
			<td><center><img width="300" src="coming_soon.png"></center></td>
			<td>
			<font size="3">AdaptFormer: Adapting Vision Transformers for Scalable Visual Recognition,
			<br>
			<i>Shoufa Chen, Chongjian Ge, Zhan Tong, Jiangliu Wang, <b>Yibing Song</b>, Jue Wang, and Ping Luo,</i>
			<br>
			Advances in Neural Information Processing Systems (<b>NeurIPS</b>) 2022
			<br>
			[<a href='https://arxiv.org/abs/2205.13535'><b>PDF</b></a>|<a href='https://github.com/ShoufaChen/AdaptFormer'><b>Project Page</b></a>] 			
			</td>			
		</tr>							
		
		
	</tbody>
	</table>
	
		
</body>

</html>

